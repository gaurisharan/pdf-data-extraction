{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7213d5c5a514d98a4d4fad7a2c2a75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from datasets import DatasetDict, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Extract Text from PDFs -----------\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text\n",
    "\n",
    "def extract_text_from_folder(folder_path):\n",
    "    all_text = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, file)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            all_text.append(text)\n",
    "    return \"\\n\".join(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Create Instruction-Based Dataset -----------\n",
    "def split_into_paragraphs(text):\n",
    "    paragraphs = re.split(r\"\\n\\s*\\n\", text)  # Split on empty lines\n",
    "    return [p.strip() for p in paragraphs if len(p.strip()) > 50]\n",
    "\n",
    "def create_instruction_format(paragraphs):\n",
    "    dataset = []\n",
    "    for para in paragraphs:\n",
    "        dataset.append({\n",
    "            \"instruction\": \"Summarize the following historical passage:\",\n",
    "            \"input\": para,\n",
    "            \"output\": \" \".join(para.split()[:50]) + \"...\"  # Placeholder summary\n",
    "        })\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Split into Train/Test (80-20) -----------\n",
    "def split_train_test(data, train_ratio=0.8):\n",
    "    random.shuffle(data)  # Shuffle for randomness\n",
    "    split_idx = int(len(data) * train_ratio)\n",
    "    train_data = data[:split_idx]\n",
    "    test_data = data[split_idx:]\n",
    "    return train_data, test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Save as JSON -----------\n",
    "def save_as_json(data, output_path):\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Upload to Hugging Face Datasets -----------\n",
    "def upload_to_huggingface(train_json, test_json, dataset_name):\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": Dataset.from_json(train_json),\n",
    "        \"test\": Dataset.from_json(test_json),\n",
    "    })\n",
    "    dataset.push_to_hub(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5fa456451645369e9d6b21399156e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680f0f0c56da4e909dd33be06e163a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815c1078d02c450cba8574f97247fcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1791e670b23e4bd8a9fe73fb8b5211fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b6ea61b8514070b790b9f96faee2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b46e25c3b344e978a8d198c88152526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset processing and upload completed! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "# ----------- Main Execution -----------\n",
    "folder_path = \"C:/Users/Admin/Desktop/pdf_folder\"  # Change this to your folder\n",
    "train_json = \"history_train.json\"\n",
    "test_json = \"history_test.json\"\n",
    "huggingface_dataset_name = \"gauri-sharan/history-class8-dataset\"\n",
    "\n",
    "# Processing pipeline\n",
    "text_data = extract_text_from_folder(folder_path)\n",
    "paragraphs = split_into_paragraphs(text_data)\n",
    "instruction_data = create_instruction_format(paragraphs)\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = split_train_test(instruction_data)\n",
    "\n",
    "# Save train & test sets\n",
    "save_as_json(train_data, train_json)\n",
    "save_as_json(test_data, test_json)\n",
    "\n",
    "# Upload dataset\n",
    "upload_to_huggingface(train_json, test_json, huggingface_dataset_name)\n",
    "\n",
    "print(\"Dataset processing and upload completed! ðŸš€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
